{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meta_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbkQ_ukjPXV2"
      },
      "source": [
        "**This file contains the code for building up the meta model(LGBM Model)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bH3fcCCPhR8"
      },
      "source": [
        "Importing necessary files from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kql5MjdFT60"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjgmhUMTFUd9",
        "outputId": "039f56ac-6c6b-4425-d335-438d02d7af12"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njm7tLnOF2W8"
      },
      "source": [
        "import pickle\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from tqdm import tqdm\r\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS4hMYCGF46R"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\r\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\r\n",
        "import lightgbm as lgb\r\n",
        "from lightgbm import LGBMRegressor\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "import xgboost\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from scipy.stats import uniform,randint\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdP61CTjF6HO"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjxubVnrPoRf"
      },
      "source": [
        "**Here the predictions from all the base models are concatenated which works as the input for my meta model.This prediction is done on the other 50% dataset.The test prediction is done on the intial 20% dataset which is the test set and after final training of my meta model it predicts on the predictions of the test set from the base model which can be used to evaluate the final preformance of my meta model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFHTqyNkF6bk"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/s1_pred_df.txt','rb')\r\n",
        "s1_pred_df=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyF8-vsdF62S"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/s1_test_df.txt','rb')\r\n",
        "s1_test_df=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Viu8ErF7JO"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/s2_predict_df.txt','rb')\r\n",
        "s2_pred_df=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEWyrcy7F7p_"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/s2_predict_test_df.txt','rb')\r\n",
        "s2_test_df=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DODZ3jv2H0CQ"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/s3_pred_df.txt','rb')\r\n",
        "s3_pred_df=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znmhrcjqIDQ4"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/s3_test_df.txt','rb')\r\n",
        "s3_test_df=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbe9ClHcISvN"
      },
      "source": [
        "file=open('/content/drive/MyDrive/Project Energy Consumption/df_tr_red_final_modified.txt','rb')\r\n",
        "df_tr_red_final=pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpxcXx5UIl3b"
      },
      "source": [
        "df_tr_red_final.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SboAybRAIoKT"
      },
      "source": [
        "df_tr_red_final.drop(['index','timestamp'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NzbXb3uIqp5"
      },
      "source": [
        "df_tr_red_final.drop('level_0',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNDVSVL_QcJL"
      },
      "source": [
        "**Target Transformation**\r\n",
        "\r\n",
        "1.   Here I am taking log1p of the meter readings and then I will evaluate my base models on RMSE which by default becomes the RMSLE(The evaluation metric on which we have to evaluate on).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC3UtYAoIs6q"
      },
      "source": [
        "y_tr=np.log1p(df_tr_red_final['meter_reading'])\r\n",
        "df_tr_red_final.drop('meter_reading',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVpuLSiYQzlW"
      },
      "source": [
        "**Drpping the features which are not important**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOvQEzABIvXg"
      },
      "source": [
        "df_tr_red_final.drop(['cloud_coverage','sea_level_pressure','wind_direction','wind_speed',\r\n",
        "                      'is_summer_month','is_pub_holiday'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE2ldiO8Ixt6"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(df_tr_red_final,y_tr,test_size=0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yco2CcD0I0kj"
      },
      "source": [
        "X_train_d1,X_train_d2,y_train_d1,y_train_d2=train_test_split(X_train,y_train,test_size=0.5,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHpyVevPRJ0K"
      },
      "source": [
        "**Concatenating the predicted data from the base model which serves as an input for my meta model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbToD7aFI4Fz"
      },
      "source": [
        "X_train_d2_pred=pd.concat([s1_pred_df,s2_pred_df,s3_pred_df],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ6V76w7RV03"
      },
      "source": [
        "**Hyperparameter tuning of my meta model(LGBM Regressor)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joBkvmKTJhOg",
        "outputId": "902f022d-1451-4d06-e409-5c4eca65ef83"
      },
      "source": [
        "params={'max_depth':[3,5,7,9,11],\r\n",
        "'learning_rate':[0.1,0.01,0.03,0.05],\r\n",
        "'colsample_bytree':[0.7,0.8,0.9,1.0],\r\n",
        "'n_estimators':[300,500,800,1200],\r\n",
        "'min_child_samples':[50,100,200,300,500]}\r\n",
        "\r\n",
        "\r\n",
        "lgb_reg=LGBMRegressor()\r\n",
        "random_lgb=RandomizedSearchCV(lgb_reg,params,n_iter=8,scoring='neg_root_mean_squared_error',cv=3,verbose=24,random_state=5,n_jobs=-1)\r\n",
        "random_lgb.fit(X_train_d2_pred,y_train_d2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  9.9min\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed: 10.3min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 10.5min\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed: 21.7min\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 21.7min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 22.2min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 23.0min\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed: 25.5min\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 26.2min\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 28.8min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 29.7min\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 29.8min\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 30.9min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 32.9min\n",
            "[Parallel(n_jobs=-1)]: Done  19 out of  24 | elapsed: 33.9min remaining:  8.9min\n",
            "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed: 35.8min remaining:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 37.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=LGBMRegressor(boosting_type='gbdt',\n",
              "                                           class_weight=None,\n",
              "                                           colsample_bytree=1.0,\n",
              "                                           importance_type='split',\n",
              "                                           learning_rate=0.1, max_depth=-1,\n",
              "                                           min_child_samples=20,\n",
              "                                           min_child_weight=0.001,\n",
              "                                           min_split_gain=0.0, n_estimators=100,\n",
              "                                           n_jobs=-1, num_leaves=31,\n",
              "                                           objective=None, random_state=None,\n",
              "                                           reg_alpha=0.0, reg_lambda=0.0,\n",
              "                                           silen...\n",
              "                   iid='deprecated', n_iter=8, n_jobs=-1,\n",
              "                   param_distributions={'colsample_bytree': [0.7, 0.8, 0.9,\n",
              "                                                             1.0],\n",
              "                                        'learning_rate': [0.1, 0.01, 0.03,\n",
              "                                                          0.05],\n",
              "                                        'max_depth': [3, 5, 7, 9, 11],\n",
              "                                        'min_child_samples': [50, 100, 200, 300,\n",
              "                                                              500],\n",
              "                                        'n_estimators': [300, 500, 800, 1200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=5, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring='neg_root_mean_squared_error', verbose=24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf5dNXNFRfUz"
      },
      "source": [
        "**Finding the best params from the random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63iq0aQ7Kcq4",
        "outputId": "8310563e-167f-462d-8442-d713de6cc21b"
      },
      "source": [
        "random_lgb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.9,\n",
              " 'learning_rate': 0.05,\n",
              " 'max_depth': 7,\n",
              " 'min_child_samples': 50,\n",
              " 'n_estimators': 800}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWl2x7KFSucg",
        "outputId": "0e3c9acb-8af2-4bc4-e090-27a92098eae4"
      },
      "source": [
        "random_lgb.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6108507543085028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKT1hwKARmdR"
      },
      "source": [
        "**Fitting the model with the best params on the predictions from the base model and using the ground truth values from the other 50% data set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmyxON-RUPly",
        "outputId": "e8993eb3-ac0b-4af4-eace-a8d802c02a9b"
      },
      "source": [
        "meta_model=LGBMRegressor(n_estimators=800,min_child_samples=50,max_depth=7,learning_rate=0.05,colsample_bytree=0.9,n_jobs=-1)\r\n",
        "meta_model.fit(X_train_d2_pred,y_train_d2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n",
              "              importance_type='split', learning_rate=0.05, max_depth=7,\n",
              "              min_child_samples=50, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=800, n_jobs=-1, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7vJoMoaR2LA"
      },
      "source": [
        "**Using the predictions on the test set from the base models to evaluate my meta model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCnbKht4TvqL"
      },
      "source": [
        "predictions=pd.concat([s1_test_df,s2_test_df,s3_test_df],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsF7fE1UBbi"
      },
      "source": [
        "test_pred=meta_model.predict(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKGUAU4JUDCo",
        "outputId": "f2aa789d-ac54-4053-fe58-6f336ff6c6b4"
      },
      "source": [
        "np.sqrt(mean_squared_error(y_test,test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.609958338958561"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PG7nVPaV741"
      },
      "source": [
        "filename='meta_model.txt'\r\n",
        "my_file=open(filename,'wb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcTGgqI3WEg7"
      },
      "source": [
        "pickle.dump(meta_model,my_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we7YFJQRSIUe"
      },
      "source": [
        "                                                             **End of Notebook**"
      ]
    }
  ]
}